services:
  ai:
    profiles: ["gpu-only"] # GPU가 있는 경우에만 실행 (--profile gpu-only)
    build:
      context: ./ai
      dockerfile: Dockerfile
    container_name: overlang_ai
    volumes:
      - ./ai:/app/ai
    environment:
      - PYTHONPATH=/app
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    ports:
      - "8000:8000"
    command: uvicorn ai.api.app:app --host 0.0.0.0 --port 8000 --reload

  ai-worker:
    profiles: ["gpu-only"]
    build:
      context: ./ai
      dockerfile: Dockerfile
    container_name: overlang_ai_worker
    volumes:
      - ./ai:/app/ai
    environment:
      - PYTHONPATH=/app
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      - redis
      - ai
    command: celery -A ai.worker.celery_app worker --loglevel=info --pool=solo

  # Database & Cache
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  postgres:
    image: postgres:16-alpine
    container_name: overlang_postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: overlang
      POSTGRES_USER: overlang
      POSTGRES_PASSWORD: overlang1234
    volumes:
      - overlang_pgdata:/var/lib/postgresql/data

volumes:
  overlang_pgdata:
